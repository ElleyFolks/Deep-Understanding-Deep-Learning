{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# importing iris dataset\n",
    "import seaborn as sns\n",
    "iris_dataset = sns.load_dataset('iris')\n",
    "\n",
    "# direct access to torch.nn functions (without using classes)\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Cross Validation!\n",
    "#### What is cross validation?\n",
    "A technique to minimize over-fitting by validating model performance across different data subsets. These data subsets are often divided into these sections:\n",
    "1. *training set* (used to train model) - data the model is trained on, backprop is used, weights are changed.\n",
    "2. *dev set (aka hold-out set)* - tests model accuracy, is used to fine-tune the model, no learning with this data.\n",
    "3. *test set* - is used as the final test for the model, no learning with this data. Used to address overfitting, tests model generalizability (ability to perform on new data).\n",
    "\n",
    "## In this Project:\n",
    "#### Cross Validation will be performed by manually dividing up the data with numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting from pandas dataframe to pytorch tensor\n",
    "torched_iris_dataset= torch.tensor(iris_dataset[iris_dataset.columns[0:4]].values).float() # only use first 4 columns, because last column is outcome variable or datatype.\n",
    "\n",
    "# numeric transformation - transforming species name to a number (0-2)\n",
    "iris_labels = torch.zeros(len(torched_iris_dataset), dtype=torch.long) # species 'setosa' will remain 0.\n",
    "iris_labels[iris_dataset.species=='versicolor'] = 1\n",
    "iris_labels[iris_dataset.species=='virginica'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating Iris Dataset into Training and Testing sets\n",
    "#### To keep the subsections / sets of data **representative** of the *original dataset*, the training set needs to be **randomly sampled**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw dataset distribution:  tensor(1.)\n",
      "Training set distribution:  tensor(0.9833)\n",
      "Testing set distribution:  tensor(1.0667)\n",
      "Shape of iris dataset:  torch.Size([150, 4])\n",
      "Shape of training set:  torch.Size([120, 4])\n",
      "Shape of testing set:  torch.Size([30, 4])\n"
     ]
    }
   ],
   "source": [
    "# Data division parameters\n",
    "train_data_ratio = 0.8 # 80% of the data will be used for training\n",
    "number_of_samples = int(len(iris_labels)*train_data_ratio) # number of samples for training\n",
    "\n",
    "# Initializing a vector to store this information. Boolean indicates if sample is included in training set.\n",
    "training_set_bool = np.zeros(len(iris_labels), dtype=bool)\n",
    "\n",
    "# Randomly selecting samples for training\n",
    "random_training_samples = np.random.choice(range(len(iris_labels)),number_of_samples,replace=False)\n",
    "\n",
    "training_set_bool[random_training_samples] = True\n",
    "\n",
    "# Testing if samples are representative of the dataset. \n",
    "# An avg ~ 1 is expected (because of an equal distribution of 0, 1, 2 for the flower labels).\n",
    "raw_dataset_distribution = torch.mean(iris_labels.float())\n",
    "training_set_distribution = torch.mean(iris_labels[training_set_bool].float())\n",
    "testing_set_distribution = torch.mean(iris_labels[~training_set_bool].float())\n",
    "\n",
    "print('Raw dataset distribution: ', raw_dataset_distribution)\n",
    "print('Training set distribution: ', training_set_distribution)\n",
    "print('Testing set distribution: ', testing_set_distribution)\n",
    "\n",
    "# Examining the shape of each dataset\n",
    "print('Shape of iris dataset: ', torched_iris_dataset.shape)\n",
    "print('Shape of training set: ', torched_iris_dataset[training_set_bool].shape)\n",
    "print('Shape of testing set: ', torched_iris_dataset[~training_set_bool].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture (not the focus of this experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_iris = nn.Sequential(\n",
    "    nn.Linear(4,64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,3)\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(ANN_iris.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Train the Model\n",
    "- The only major changes to the function have been exclusively using the training data and the corresponding labels, instead of training on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_classification_training(model, loss_function, m_optimizer, input_data, input_labels, epochs = 1000):\n",
    "    \n",
    "    # parameters\n",
    "    losses = torch.zeros(epochs)\n",
    "    per_epoch_accuracy = []\n",
    "    \n",
    "    # training\n",
    "    for epoch_IDX in range(epochs):\n",
    "        # forward pass\n",
    "        y_hat = model(input_data) # only training data\n",
    "        \n",
    "        # calculating loss\n",
    "        loss = loss_function(y_hat, input_labels)\n",
    "        losses[epoch_IDX] = loss\n",
    "        # backprop\n",
    "        m_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        m_optimizer.step()\n",
    "\n",
    "        # calculating accuracy at each epoch\n",
    "        matches = torch.argmax(y_hat, axis=1) == input_labels.float() # converting to booleans (T / F)\n",
    "        matches_num = matches.float()                         # convert bools to ints (0 / 1)\n",
    "        accuracy_percent = 100*torch.mean(matches_num)        # average of correct matches\n",
    "        per_epoch_accuracy.append(accuracy_percent)\n",
    "\n",
    "    # final forward pass\n",
    "    final_predictions = model(input_data)\n",
    "\n",
    "    # overall accuracy\n",
    "    predicted_lables = torch.argmax(final_predictions, axis=1)\n",
    "    total_accuracy = 100*torch.mean((predicted_lables==input_labels).float())\n",
    "\n",
    "    return final_predictions, losses, per_epoch_accuracy, total_accuracy, y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model params\n",
    "set_learning_rate = 0.01\n",
    "\n",
    "# training model\n",
    "final_predictions, losses, per_epoch_accuracy, model_accuracy, y_hat = ANN_classification_training(\n",
    "    model= ANN_iris,\n",
    "    loss_function= loss_function,\n",
    "    m_optimizer= optimizer,\n",
    "    input_data= torched_iris_dataset[training_set_bool], # only training data\n",
    "    input_labels= iris_labels[training_set_bool], # only training data labels\n",
    "    epochs= 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  tensor(99.1667)\n",
      "Testing accuracy:  tensor(93.3333)\n"
     ]
    }
   ],
   "source": [
    "# Final Forward Pass with training data\n",
    "predictions = ANN_iris(torched_iris_dataset[training_set_bool])\n",
    "training_accuracy = 100*torch.mean((torch.argmax(predictions, axis=1)==iris_labels[training_set_bool]).float())\n",
    "print('Training accuracy: ', training_accuracy)\n",
    "\n",
    "# Final Forward Pass with testing data\n",
    "predictions = ANN_iris(torched_iris_dataset[~training_set_bool])\n",
    "testing_accuracy = 100*torch.mean((torch.argmax(predictions, axis=1)==iris_labels[~training_set_bool]).float())\n",
    "print('Testing accuracy: ', testing_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- An interesting result here is that occasionally the **testing** accuracy can *actually be higher* than the **training** accuracy!\n",
    "- With smaller models and smaller datasets this can happen, and it's not unusual in this situation. This kind of behavior is not desirable in larger models with more data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
